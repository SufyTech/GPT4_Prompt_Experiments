# GPT-4 Prompt Experiments

This repository contains my self-initiated exploration of GPT-4 prompts for learning prompt engineering and LLM behavior evaluation. The experiments focus on prompt design, accuracy improvement, and response evaluation.

## Key Learnings:
- Iterative prompt design improves relevance and accuracy.
- Few-shot and zero-shot prompting guides model behavior.
- Clear and structured prompts generate more precise outputs.

## Experiments:
1. Basic Prompt Variation
2. Tone and Style Variation
3. Prompt Clarity Test

Screenshots and notebook files demonstrate the outputs of GPT-4 and my observations.

## Next Steps:
- Experiment with context-based prompts and retrieval-augmented generation (RAG).
- Explore AI for socially impactful solutions.
